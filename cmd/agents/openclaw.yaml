# OpenClaw Agent Configuration
# ================================
# OpenClaw personal AI assistant with gateway compression support
# Uses fast_setup.yaml with all optimizations enabled:
#   - Lingua: Semantic summarization
#   - Compresr: Tool output & discovery
#
# Usage:
#   ./start_agent.sh openclaw
#
# OpenClaw needs its own gateway running for the TUI to work.
# This config starts OpenClaw's gateway, then opens the TUI.
# LLM calls are routed through our Context Gateway via providers config.

agent:
  name: "openclaw"
  display_name: "OpenClaw"
  description: "OpenClaw personal AI assistant with Compresr compression"
  config: "fast_setup.yaml"

  # Default model for proxy config; actual model selection is handled by OpenClaw's own TUI
  default_model: "anthropic/claude-opus-4-5"

  environment:
    # Both providers routed through Context Gateway
    - name: "ANTHROPIC_API_KEY"
      value: "${ANTHROPIC_API_KEY}"
    - name: "ANTHROPIC_BASE_URL"
      value: "http://localhost:${GATEWAY_PORT}"
    - name: "OPENAI_API_KEY"
      value: "${OPENAI_API_KEY}"
    - name: "OPENAI_BASE_URL"
      value: "http://localhost:${GATEWAY_PORT}"

  command:
    check_cmd: ["which", "openclaw"]
    run: "openclaw"
    args: ["tui", "--token", "localdev"]
    # pre_run is handled by start_agent.sh which creates the config with selected model
    install_cmd: ["npm", "install", "-g", "openclaw@latest"]
    fallback_message: "OpenClaw not found."
